{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import exp\n",
    "plt.rcParams[\"figure.figsize\"]=(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-119.366669</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-101.108044</td>\n",
       "      <td>97.777159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-130.278658</td>\n",
       "      <td>106.767654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-114.703415</td>\n",
       "      <td>101.195477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-119.366669</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          x2  y\n",
       "0 -119.366669  115.000000  1\n",
       "1 -101.108044   97.777159  1\n",
       "2 -130.278658  106.767654  1\n",
       "3 -114.703415  101.195477  1\n",
       "4 -119.366669  115.000000  1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizng the dataset\n",
    "plt.scatter(data['x1'],data['y'])\n",
    "plt.show()\n",
    "\n",
    "#Divide the data into train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['x1'],data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize the data\n",
    "\n",
    "def normalize(X):\n",
    "    return X - X.mean()\n",
    "\n",
    "#Method to make predictions\n",
    "def predict(X,b0,b1):\n",
    "    return np.array([1 / (1 + exp(-1*b0 + -1*b1*x)) for x in X])\n",
    "#Logistic Regression\n",
    "def logistic_regression(X,Y):\n",
    "    \n",
    "    X = normalize(X)\n",
    "    b0 = 0\n",
    "    b1 = 0\n",
    "    l = 0.001\n",
    "    epochs = 300\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predict(X, b0, b1)\n",
    "        D_b0 = -2 * sum((Y - y_pred) * y_pred * (1 - y_pred))\n",
    "        D_b1 = -2 * sum(X * (Y - y_pred) * y_pred * (1-y_pred))\n",
    "        b0 = b0 - l * D_b0\n",
    "        b1 = b1 - l * D_b1\n",
    "    return b0, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0\n",
      "Accuracy = 0.0\n",
      "Accuracy = 0.0017953321364452424\n",
      "Accuracy = 0.003590664272890485\n",
      "Accuracy = 0.005385996409335727\n",
      "Accuracy = 0.005385996409335727\n",
      "Accuracy = 0.00718132854578097\n",
      "Accuracy = 0.00718132854578097\n",
      "Accuracy = 0.008976660682226212\n",
      "Accuracy = 0.008976660682226212\n",
      "Accuracy = 0.010771992818671455\n",
      "Accuracy = 0.012567324955116697\n",
      "Accuracy = 0.01436265709156194\n",
      "Accuracy = 0.01615798922800718\n",
      "Accuracy = 0.01615798922800718\n",
      "Accuracy = 0.017953321364452424\n",
      "Accuracy = 0.019748653500897665\n",
      "Accuracy = 0.02154398563734291\n",
      "Accuracy = 0.02333931777378815\n",
      "Accuracy = 0.02333931777378815\n",
      "Accuracy = 0.025134649910233394\n",
      "Accuracy = 0.026929982046678635\n",
      "Accuracy = 0.02872531418312388\n",
      "Accuracy = 0.02872531418312388\n",
      "Accuracy = 0.02872531418312388\n",
      "Accuracy = 0.03052064631956912\n",
      "Accuracy = 0.03231597845601436\n",
      "Accuracy = 0.03411131059245961\n",
      "Accuracy = 0.03590664272890485\n",
      "Accuracy = 0.03770197486535009\n",
      "Accuracy = 0.03770197486535009\n",
      "Accuracy = 0.03770197486535009\n",
      "Accuracy = 0.03949730700179533\n",
      "Accuracy = 0.04129263913824058\n",
      "Accuracy = 0.04308797127468582\n",
      "Accuracy = 0.04488330341113106\n",
      "Accuracy = 0.0466786355475763\n",
      "Accuracy = 0.04847396768402154\n",
      "Accuracy = 0.04847396768402154\n",
      "Accuracy = 0.04847396768402154\n",
      "Accuracy = 0.05026929982046679\n",
      "Accuracy = 0.05206463195691203\n",
      "Accuracy = 0.05385996409335727\n",
      "Accuracy = 0.05565529622980251\n",
      "Accuracy = 0.05565529622980251\n",
      "Accuracy = 0.05745062836624776\n",
      "Accuracy = 0.059245960502693\n",
      "Accuracy = 0.059245960502693\n",
      "Accuracy = 0.06104129263913824\n",
      "Accuracy = 0.06104129263913824\n",
      "Accuracy = 0.06104129263913824\n",
      "Accuracy = 0.06283662477558348\n",
      "Accuracy = 0.06463195691202872\n",
      "Accuracy = 0.06642728904847396\n",
      "Accuracy = 0.06642728904847396\n",
      "Accuracy = 0.06642728904847396\n",
      "Accuracy = 0.06642728904847396\n",
      "Accuracy = 0.06822262118491922\n",
      "Accuracy = 0.06822262118491922\n",
      "Accuracy = 0.07001795332136446\n",
      "Accuracy = 0.0718132854578097\n",
      "Accuracy = 0.07360861759425494\n",
      "Accuracy = 0.07360861759425494\n",
      "Accuracy = 0.07360861759425494\n",
      "Accuracy = 0.07540394973070018\n",
      "Accuracy = 0.07719928186714542\n",
      "Accuracy = 0.07719928186714542\n",
      "Accuracy = 0.07719928186714542\n",
      "Accuracy = 0.07899461400359066\n",
      "Accuracy = 0.0807899461400359\n",
      "Accuracy = 0.0807899461400359\n",
      "Accuracy = 0.0807899461400359\n",
      "Accuracy = 0.0807899461400359\n",
      "Accuracy = 0.08258527827648116\n",
      "Accuracy = 0.0843806104129264\n",
      "Accuracy = 0.08617594254937164\n",
      "Accuracy = 0.08797127468581688\n",
      "Accuracy = 0.08976660682226212\n",
      "Accuracy = 0.09156193895870736\n",
      "Accuracy = 0.0933572710951526\n",
      "Accuracy = 0.09515260323159784\n",
      "Accuracy = 0.09515260323159784\n",
      "Accuracy = 0.09694793536804308\n",
      "Accuracy = 0.09874326750448834\n",
      "Accuracy = 0.10053859964093358\n",
      "Accuracy = 0.10233393177737882\n",
      "Accuracy = 0.10412926391382406\n",
      "Accuracy = 0.10412926391382406\n",
      "Accuracy = 0.1059245960502693\n",
      "Accuracy = 0.1059245960502693\n",
      "Accuracy = 0.1059245960502693\n",
      "Accuracy = 0.1059245960502693\n",
      "Accuracy = 0.10771992818671454\n",
      "Accuracy = 0.10771992818671454\n",
      "Accuracy = 0.10771992818671454\n",
      "Accuracy = 0.10771992818671454\n",
      "Accuracy = 0.10771992818671454\n",
      "Accuracy = 0.10951526032315978\n",
      "Accuracy = 0.10951526032315978\n",
      "Accuracy = 0.11131059245960502\n",
      "Accuracy = 0.11310592459605028\n",
      "Accuracy = 0.11490125673249552\n",
      "Accuracy = 0.11669658886894076\n",
      "Accuracy = 0.11669658886894076\n",
      "Accuracy = 0.11669658886894076\n",
      "Accuracy = 0.118491921005386\n",
      "Accuracy = 0.118491921005386\n",
      "Accuracy = 0.12028725314183124\n",
      "Accuracy = 0.12208258527827648\n",
      "Accuracy = 0.12387791741472172\n",
      "Accuracy = 0.12567324955116696\n",
      "Accuracy = 0.12567324955116696\n",
      "Accuracy = 0.12567324955116696\n",
      "Accuracy = 0.12567324955116696\n",
      "Accuracy = 0.12746858168761221\n",
      "Accuracy = 0.12746858168761221\n",
      "Accuracy = 0.12926391382405744\n",
      "Accuracy = 0.1310592459605027\n",
      "Accuracy = 0.13285457809694792\n",
      "Accuracy = 0.13285457809694792\n",
      "Accuracy = 0.13285457809694792\n",
      "Accuracy = 0.13285457809694792\n",
      "Accuracy = 0.13285457809694792\n",
      "Accuracy = 0.13464991023339318\n",
      "Accuracy = 0.13644524236983843\n",
      "Accuracy = 0.13824057450628366\n",
      "Accuracy = 0.1400359066427289\n",
      "Accuracy = 0.1400359066427289\n",
      "Accuracy = 0.1400359066427289\n",
      "Accuracy = 0.14183123877917414\n",
      "Accuracy = 0.1436265709156194\n",
      "Accuracy = 0.14542190305206462\n",
      "Accuracy = 0.14721723518850988\n",
      "Accuracy = 0.14721723518850988\n",
      "Accuracy = 0.1490125673249551\n",
      "Accuracy = 0.15080789946140036\n",
      "Accuracy = 0.1526032315978456\n",
      "Accuracy = 0.1526032315978456\n",
      "Accuracy = 0.15439856373429084\n",
      "Accuracy = 0.1561938958707361\n",
      "Accuracy = 0.1561938958707361\n",
      "Accuracy = 0.15798922800718132\n",
      "Accuracy = 0.15798922800718132\n",
      "Accuracy = 0.15978456014362658\n",
      "Accuracy = 0.15978456014362658\n",
      "Accuracy = 0.1615798922800718\n",
      "Accuracy = 0.16337522441651706\n",
      "Accuracy = 0.16337522441651706\n",
      "Accuracy = 0.1651705565529623\n",
      "Accuracy = 0.1651705565529623\n",
      "Accuracy = 0.16696588868940754\n",
      "Accuracy = 0.16696588868940754\n",
      "Accuracy = 0.16696588868940754\n",
      "Accuracy = 0.16696588868940754\n",
      "Accuracy = 0.16696588868940754\n",
      "Accuracy = 0.1687612208258528\n",
      "Accuracy = 0.17055655296229802\n",
      "Accuracy = 0.17055655296229802\n",
      "Accuracy = 0.17055655296229802\n",
      "Accuracy = 0.17055655296229802\n",
      "Accuracy = 0.17235188509874327\n",
      "Accuracy = 0.1741472172351885\n",
      "Accuracy = 0.1741472172351885\n",
      "Accuracy = 0.17594254937163376\n",
      "Accuracy = 0.17594254937163376\n",
      "Accuracy = 0.17773788150807898\n",
      "Accuracy = 0.17953321364452424\n",
      "Accuracy = 0.1813285457809695\n",
      "Accuracy = 0.18312387791741472\n",
      "Accuracy = 0.18312387791741472\n",
      "Accuracy = 0.18491921005385997\n",
      "Accuracy = 0.1867145421903052\n",
      "Accuracy = 0.18850987432675045\n",
      "Accuracy = 0.18850987432675045\n",
      "Accuracy = 0.19030520646319568\n",
      "Accuracy = 0.19030520646319568\n",
      "Accuracy = 0.19210053859964094\n",
      "Accuracy = 0.19389587073608616\n",
      "Accuracy = 0.19389587073608616\n",
      "Accuracy = 0.19389587073608616\n",
      "Accuracy = 0.19569120287253142\n",
      "Accuracy = 0.19748653500897667\n",
      "Accuracy = 0.19748653500897667\n",
      "Accuracy = 0.19748653500897667\n",
      "Accuracy = 0.1992818671454219\n",
      "Accuracy = 0.1992818671454219\n",
      "Accuracy = 0.20107719928186715\n",
      "Accuracy = 0.20287253141831238\n",
      "Accuracy = 0.20466786355475763\n",
      "Accuracy = 0.20646319569120286\n",
      "Accuracy = 0.20825852782764812\n",
      "Accuracy = 0.20825852782764812\n",
      "Accuracy = 0.21005385996409337\n",
      "Accuracy = 0.21005385996409337\n",
      "Accuracy = 0.21005385996409337\n",
      "Accuracy = 0.2118491921005386\n",
      "Accuracy = 0.21364452423698385\n",
      "Accuracy = 0.21364452423698385\n",
      "Accuracy = 0.21543985637342908\n",
      "Accuracy = 0.21543985637342908\n",
      "Accuracy = 0.21543985637342908\n",
      "Accuracy = 0.21543985637342908\n",
      "Accuracy = 0.21723518850987433\n",
      "Accuracy = 0.21723518850987433\n",
      "Accuracy = 0.21723518850987433\n",
      "Accuracy = 0.21903052064631956\n",
      "Accuracy = 0.22082585278276481\n",
      "Accuracy = 0.22082585278276481\n",
      "Accuracy = 0.22262118491921004\n",
      "Accuracy = 0.2244165170556553\n",
      "Accuracy = 0.2244165170556553\n",
      "Accuracy = 0.22621184919210055\n",
      "Accuracy = 0.22621184919210055\n",
      "Accuracy = 0.22800718132854578\n",
      "Accuracy = 0.22800718132854578\n",
      "Accuracy = 0.22980251346499103\n",
      "Accuracy = 0.23159784560143626\n",
      "Accuracy = 0.23159784560143626\n",
      "Accuracy = 0.2333931777378815\n",
      "Accuracy = 0.23518850987432674\n",
      "Accuracy = 0.236983842010772\n",
      "Accuracy = 0.236983842010772\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.23877917414721722\n",
      "Accuracy = 0.24057450628366248\n",
      "Accuracy = 0.24236983842010773\n",
      "Accuracy = 0.24236983842010773\n",
      "Accuracy = 0.24236983842010773\n",
      "Accuracy = 0.24416517055655296\n",
      "Accuracy = 0.2459605026929982\n",
      "Accuracy = 0.2459605026929982\n",
      "Accuracy = 0.24775583482944344\n",
      "Accuracy = 0.2495511669658887\n",
      "Accuracy = 0.2495511669658887\n",
      "Accuracy = 0.2513464991023339\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25314183123877915\n",
      "Accuracy = 0.25493716337522443\n",
      "Accuracy = 0.25493716337522443\n",
      "Accuracy = 0.25493716337522443\n",
      "Accuracy = 0.25673249551166966\n",
      "Accuracy = 0.2585278276481149\n",
      "Accuracy = 0.26032315978456017\n",
      "Accuracy = 0.26032315978456017\n",
      "Accuracy = 0.26032315978456017\n",
      "Accuracy = 0.2621184919210054\n",
      "Accuracy = 0.2639138240574506\n",
      "Accuracy = 0.2639138240574506\n",
      "Accuracy = 0.26570915619389585\n",
      "Accuracy = 0.26570915619389585\n",
      "Accuracy = 0.26570915619389585\n",
      "Accuracy = 0.26750448833034113\n",
      "Accuracy = 0.26929982046678635\n",
      "Accuracy = 0.2710951526032316\n",
      "Accuracy = 0.2710951526032316\n",
      "Accuracy = 0.27289048473967686\n",
      "Accuracy = 0.2746858168761221\n",
      "Accuracy = 0.2746858168761221\n",
      "Accuracy = 0.2764811490125673\n",
      "Accuracy = 0.27827648114901254\n",
      "Accuracy = 0.2800718132854578\n",
      "Accuracy = 0.28186714542190305\n",
      "Accuracy = 0.2836624775583483\n",
      "Accuracy = 0.2836624775583483\n",
      "Accuracy = 0.28545780969479356\n",
      "Accuracy = 0.28545780969479356\n",
      "Accuracy = 0.28545780969479356\n",
      "Accuracy = 0.28545780969479356\n",
      "Accuracy = 0.28545780969479356\n",
      "Accuracy = 0.2872531418312388\n",
      "Accuracy = 0.289048473967684\n",
      "Accuracy = 0.289048473967684\n",
      "Accuracy = 0.29084380610412924\n",
      "Accuracy = 0.2926391382405745\n",
      "Accuracy = 0.29443447037701975\n",
      "Accuracy = 0.296229802513465\n",
      "Accuracy = 0.2980251346499102\n",
      "Accuracy = 0.2998204667863555\n",
      "Accuracy = 0.2998204667863555\n",
      "Accuracy = 0.2998204667863555\n",
      "Accuracy = 0.3016157989228007\n",
      "Accuracy = 0.3016157989228007\n",
      "Accuracy = 0.30341113105924594\n",
      "Accuracy = 0.3052064631956912\n",
      "Accuracy = 0.3052064631956912\n",
      "Accuracy = 0.30700179533213645\n",
      "Accuracy = 0.3087971274685817\n",
      "Accuracy = 0.3105924596050269\n",
      "Accuracy = 0.3105924596050269\n",
      "Accuracy = 0.3105924596050269\n",
      "Accuracy = 0.3123877917414722\n",
      "Accuracy = 0.3141831238779174\n",
      "Accuracy = 0.3141831238779174\n",
      "Accuracy = 0.3141831238779174\n",
      "Accuracy = 0.31597845601436264\n",
      "Accuracy = 0.31597845601436264\n",
      "Accuracy = 0.3177737881508079\n",
      "Accuracy = 0.31956912028725315\n",
      "Accuracy = 0.31956912028725315\n",
      "Accuracy = 0.31956912028725315\n",
      "Accuracy = 0.3213644524236984\n",
      "Accuracy = 0.3231597845601436\n",
      "Accuracy = 0.3231597845601436\n",
      "Accuracy = 0.3249551166965889\n",
      "Accuracy = 0.3267504488330341\n",
      "Accuracy = 0.32854578096947934\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.3303411131059246\n",
      "Accuracy = 0.33213644524236985\n",
      "Accuracy = 0.33213644524236985\n",
      "Accuracy = 0.33213644524236985\n",
      "Accuracy = 0.3339317773788151\n",
      "Accuracy = 0.3339317773788151\n",
      "Accuracy = 0.3357271095152603\n",
      "Accuracy = 0.3375224416517056\n",
      "Accuracy = 0.3375224416517056\n",
      "Accuracy = 0.3393177737881508\n",
      "Accuracy = 0.34111310592459604\n",
      "Accuracy = 0.34111310592459604\n",
      "Accuracy = 0.34290843806104127\n",
      "Accuracy = 0.34290843806104127\n",
      "Accuracy = 0.34470377019748655\n",
      "Accuracy = 0.3464991023339318\n",
      "Accuracy = 0.3464991023339318\n",
      "Accuracy = 0.3464991023339318\n",
      "Accuracy = 0.348294434470377\n",
      "Accuracy = 0.348294434470377\n",
      "Accuracy = 0.348294434470377\n",
      "Accuracy = 0.3500897666068223\n",
      "Accuracy = 0.3518850987432675\n",
      "Accuracy = 0.35368043087971274\n",
      "Accuracy = 0.35368043087971274\n",
      "Accuracy = 0.35368043087971274\n",
      "Accuracy = 0.35368043087971274\n",
      "Accuracy = 0.35547576301615796\n",
      "Accuracy = 0.35547576301615796\n",
      "Accuracy = 0.35727109515260325\n",
      "Accuracy = 0.35727109515260325\n",
      "Accuracy = 0.35727109515260325\n",
      "Accuracy = 0.3590664272890485\n",
      "Accuracy = 0.3590664272890485\n",
      "Accuracy = 0.3590664272890485\n",
      "Accuracy = 0.3608617594254937\n",
      "Accuracy = 0.362657091561939\n",
      "Accuracy = 0.362657091561939\n",
      "Accuracy = 0.362657091561939\n",
      "Accuracy = 0.3644524236983842\n",
      "Accuracy = 0.36624775583482944\n",
      "Accuracy = 0.36804308797127466\n",
      "Accuracy = 0.36804308797127466\n",
      "Accuracy = 0.36983842010771995\n",
      "Accuracy = 0.37163375224416517\n",
      "Accuracy = 0.3734290843806104\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3752244165170557\n",
      "Accuracy = 0.3770197486535009\n",
      "Accuracy = 0.37881508078994613\n",
      "Accuracy = 0.38061041292639136\n",
      "Accuracy = 0.38061041292639136\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38240574506283664\n",
      "Accuracy = 0.38420107719928187\n",
      "Accuracy = 0.38420107719928187\n",
      "Accuracy = 0.38420107719928187\n",
      "Accuracy = 0.38420107719928187\n",
      "Accuracy = 0.3859964093357271\n",
      "Accuracy = 0.3877917414721723\n",
      "Accuracy = 0.3877917414721723\n",
      "Accuracy = 0.3895870736086176\n",
      "Accuracy = 0.39138240574506283\n",
      "Accuracy = 0.39138240574506283\n",
      "Accuracy = 0.39138240574506283\n",
      "Accuracy = 0.39317773788150806\n",
      "Accuracy = 0.39317773788150806\n",
      "Accuracy = 0.39317773788150806\n",
      "Accuracy = 0.39317773788150806\n",
      "Accuracy = 0.39497307001795334\n",
      "Accuracy = 0.39676840215439857\n",
      "Accuracy = 0.39676840215439857\n",
      "Accuracy = 0.3985637342908438\n",
      "Accuracy = 0.400359066427289\n",
      "Accuracy = 0.4021543985637343\n",
      "Accuracy = 0.40394973070017953\n",
      "Accuracy = 0.40574506283662476\n",
      "Accuracy = 0.40754039497307004\n",
      "Accuracy = 0.40754039497307004\n",
      "Accuracy = 0.40933572710951527\n",
      "Accuracy = 0.40933572710951527\n",
      "Accuracy = 0.40933572710951527\n",
      "Accuracy = 0.4111310592459605\n",
      "Accuracy = 0.4129263913824057\n",
      "Accuracy = 0.414721723518851\n",
      "Accuracy = 0.414721723518851\n",
      "Accuracy = 0.41651705565529623\n",
      "Accuracy = 0.41651705565529623\n",
      "Accuracy = 0.41831238779174146\n",
      "Accuracy = 0.42010771992818674\n",
      "Accuracy = 0.42190305206463197\n",
      "Accuracy = 0.4236983842010772\n",
      "Accuracy = 0.4254937163375224\n",
      "Accuracy = 0.4254937163375224\n",
      "Accuracy = 0.4272890484739677\n",
      "Accuracy = 0.4272890484739677\n",
      "Accuracy = 0.4272890484739677\n",
      "Accuracy = 0.4272890484739677\n",
      "Accuracy = 0.42908438061041293\n",
      "Accuracy = 0.42908438061041293\n",
      "Accuracy = 0.42908438061041293\n",
      "Accuracy = 0.43087971274685816\n",
      "Accuracy = 0.43087971274685816\n",
      "Accuracy = 0.4326750448833034\n",
      "Accuracy = 0.43447037701974867\n",
      "Accuracy = 0.43447037701974867\n",
      "Accuracy = 0.43447037701974867\n",
      "Accuracy = 0.4362657091561939\n",
      "Accuracy = 0.4380610412926391\n",
      "Accuracy = 0.4380610412926391\n",
      "Accuracy = 0.4380610412926391\n",
      "Accuracy = 0.4380610412926391\n",
      "Accuracy = 0.4398563734290844\n",
      "Accuracy = 0.4398563734290844\n",
      "Accuracy = 0.44165170556552963\n",
      "Accuracy = 0.44344703770197486\n",
      "Accuracy = 0.4452423698384201\n",
      "Accuracy = 0.4452423698384201\n",
      "Accuracy = 0.44703770197486536\n",
      "Accuracy = 0.4488330341113106\n",
      "Accuracy = 0.4488330341113106\n",
      "Accuracy = 0.4488330341113106\n",
      "Accuracy = 0.4488330341113106\n",
      "Accuracy = 0.4506283662477558\n",
      "Accuracy = 0.4506283662477558\n",
      "Accuracy = 0.4506283662477558\n",
      "Accuracy = 0.4506283662477558\n",
      "Accuracy = 0.4524236983842011\n",
      "Accuracy = 0.4542190305206463\n",
      "Accuracy = 0.45601436265709155\n",
      "Accuracy = 0.4578096947935368\n",
      "Accuracy = 0.4578096947935368\n",
      "Accuracy = 0.4578096947935368\n",
      "Accuracy = 0.45960502692998206\n",
      "Accuracy = 0.4614003590664273\n",
      "Accuracy = 0.4614003590664273\n",
      "Accuracy = 0.4631956912028725\n",
      "Accuracy = 0.4649910233393178\n",
      "Accuracy = 0.466786355475763\n",
      "Accuracy = 0.466786355475763\n",
      "Accuracy = 0.466786355475763\n",
      "Accuracy = 0.46858168761220825\n",
      "Accuracy = 0.46858168761220825\n",
      "Accuracy = 0.4703770197486535\n",
      "Accuracy = 0.47217235188509876\n",
      "Accuracy = 0.473967684021544\n",
      "Accuracy = 0.4757630161579892\n",
      "Accuracy = 0.47755834829443444\n",
      "Accuracy = 0.4793536804308797\n",
      "Accuracy = 0.48114901256732495\n",
      "Accuracy = 0.48114901256732495\n",
      "Accuracy = 0.4829443447037702\n",
      "Accuracy = 0.48473967684021546\n",
      "Accuracy = 0.4865350089766607\n",
      "Accuracy = 0.4865350089766607\n",
      "Accuracy = 0.4883303411131059\n",
      "Accuracy = 0.49012567324955114\n",
      "Accuracy = 0.4919210053859964\n",
      "Accuracy = 0.4919210053859964\n",
      "Accuracy = 0.49371633752244165\n",
      "Accuracy = 0.4955116696588869\n",
      "Accuracy = 0.4955116696588869\n",
      "Accuracy = 0.4955116696588869\n",
      "Accuracy = 0.49730700179533216\n",
      "Accuracy = 0.4991023339317774\n",
      "Accuracy = 0.5008976660682226\n",
      "Accuracy = 0.5008976660682226\n",
      "Accuracy = 0.5008976660682226\n",
      "Accuracy = 0.5008976660682226\n",
      "Accuracy = 0.5026929982046678\n",
      "Accuracy = 0.5044883303411131\n",
      "Accuracy = 0.5044883303411131\n",
      "Accuracy = 0.5044883303411131\n",
      "Accuracy = 0.5062836624775583\n",
      "Accuracy = 0.5062836624775583\n",
      "Accuracy = 0.5080789946140036\n",
      "Accuracy = 0.5098743267504489\n",
      "Accuracy = 0.5098743267504489\n",
      "Accuracy = 0.5116696588868941\n",
      "Accuracy = 0.5134649910233393\n",
      "Accuracy = 0.5152603231597845\n",
      "Accuracy = 0.5170556552962298\n",
      "Accuracy = 0.518850987432675\n",
      "Accuracy = 0.5206463195691203\n",
      "Accuracy = 0.5224416517055656\n",
      "Accuracy = 0.5242369838420108\n",
      "Accuracy = 0.526032315978456\n",
      "Accuracy = 0.526032315978456\n",
      "Accuracy = 0.5278276481149012\n",
      "Accuracy = 0.5296229802513465\n",
      "Accuracy = 0.5314183123877917\n",
      "Accuracy = 0.5314183123877917\n",
      "Accuracy = 0.5314183123877917\n",
      "Accuracy = 0.5314183123877917\n",
      "Accuracy = 0.533213644524237\n",
      "Accuracy = 0.533213644524237\n",
      "Accuracy = 0.5350089766606823\n",
      "Accuracy = 0.5368043087971275\n",
      "Accuracy = 0.5385996409335727\n",
      "Accuracy = 0.5385996409335727\n",
      "Accuracy = 0.5403949730700179\n",
      "Accuracy = 0.5403949730700179\n",
      "Accuracy = 0.5421903052064632\n",
      "Accuracy = 0.5421903052064632\n",
      "Accuracy = 0.5439856373429084\n",
      "Accuracy = 0.5457809694793537\n",
      "Accuracy = 0.5457809694793537\n",
      "Accuracy = 0.547576301615799\n",
      "Accuracy = 0.5493716337522442\n",
      "Accuracy = 0.5511669658886894\n",
      "Accuracy = 0.5529622980251346\n",
      "Accuracy = 0.5547576301615799\n",
      "Accuracy = 0.5547576301615799\n",
      "Accuracy = 0.5547576301615799\n",
      "Accuracy = 0.5565529622980251\n",
      "Accuracy = 0.5565529622980251\n",
      "Accuracy = 0.5583482944344704\n",
      "Accuracy = 0.5601436265709157\n",
      "Accuracy = 0.5601436265709157\n",
      "Accuracy = 0.5601436265709157\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "b0, b1 = logistic_regression(x_train,y_train)\n",
    "\n",
    "#Making Predictions\n",
    "x_test_norm = normalize(x_test)\n",
    "y_pred = predict(x_test_norm, b0, b1)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.scatter(x_test, y_pred, c=\"red\")\n",
    "plt.show()\n",
    "\n",
    "#The accuracy\n",
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test.iloc[i]:\n",
    "        accuracy += 1\n",
    "    print(f\"Accuracy = {accuracy / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sweet Home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c681608a5057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlr_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred_sk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Making predictions using scikit learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train.values.reshape(-1,1),y_train.values.reshape(-1,1))\n",
    "\n",
    "y_pred_sk = lr_model.predict(x_test.values.reshape(-1,1))\n",
    "plt.clf()\n",
    "plt.scatter(x_test,y_test)\n",
    "plt.scatter(x_test,y_pred_sk,c=\"green\")\n",
    "plt.show()\n",
    "\n",
    "#Accuracy\n",
    "print(f\"Accuracy = {lr_model.score(x_test.values.reshape(-1,1),y_test.values.reshape(-1,1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
